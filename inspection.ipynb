{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from IPython.core.display_functions import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.item_embedding = layers.Embedding(\n",
    "            num_items,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.item_bias = layers.Embedding(num_items, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        item_vector = self.item_embedding(inputs[:, 1])\n",
    "        item_bias = self.item_bias(inputs[:, 1])\n",
    "        dot_user_item = tf.tensordot(user_vector, item_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_item + user_bias + item_bias\n",
    "        # The sigmoid activation forces the rating to between 0 and 1\n",
    "        return tf.nn.sigmoid(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def df_encoding(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    user_ids = df[\"userId\"].unique().tolist()\n",
    "    user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "    userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "    item_ids = df[\"itemId\"].unique().tolist()\n",
    "    item2item_encoded = {x: i for i, x in enumerate(item_ids)}\n",
    "    item_encoded2item = {i: x for i, x in enumerate(item_ids)}\n",
    "    df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
    "    df[\"item\"] = df[\"itemId\"].map(item2item_encoded)\n",
    "\n",
    "    num_users = len(user2user_encoded)\n",
    "    num_items = len(item_encoded2item)\n",
    "    df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
    "    # min and max ratings will be used to normalize the ratings later\n",
    "    min_rating = min(df[\"rating\"])\n",
    "    max_rating = max(df[\"rating\"])\n",
    "\n",
    "\n",
    "    return df, num_users, num_items, min_rating, max_rating"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         userId  itemId  rating                 date\n0        cgexjc  682978       4  2017-08-13 13:23:35\n1        cgexjc  320898       4  2019-01-18 15:56:07\n2        cgexjc   29028       4  2017-08-13 14:03:55\n3        cgexjc  399148       5  2017-08-13 13:59:51\n4        cgexjc  734055       4  2019-01-18 15:37:29\n...         ...     ...     ...                  ...\n8612102  blqyzd  148210       1  2017-08-05 14:15:09\n8612103  blqyzd  735535       4  2017-08-05 14:14:35\n8612104  blqyzd  124242       3  2017-08-05 14:25:33\n8612105  blqyzd  948393       4  2017-08-05 13:25:21\n8612106  blqyzd  163356       4  2017-08-05 14:24:57\n\n[8612107 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>itemId</th>\n      <th>rating</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cgexjc</td>\n      <td>682978</td>\n      <td>4</td>\n      <td>2017-08-13 13:23:35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cgexjc</td>\n      <td>320898</td>\n      <td>4</td>\n      <td>2019-01-18 15:56:07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cgexjc</td>\n      <td>29028</td>\n      <td>4</td>\n      <td>2017-08-13 14:03:55</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cgexjc</td>\n      <td>399148</td>\n      <td>5</td>\n      <td>2017-08-13 13:59:51</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cgexjc</td>\n      <td>734055</td>\n      <td>4</td>\n      <td>2019-01-18 15:37:29</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8612102</th>\n      <td>blqyzd</td>\n      <td>148210</td>\n      <td>1</td>\n      <td>2017-08-05 14:15:09</td>\n    </tr>\n    <tr>\n      <th>8612103</th>\n      <td>blqyzd</td>\n      <td>735535</td>\n      <td>4</td>\n      <td>2017-08-05 14:14:35</td>\n    </tr>\n    <tr>\n      <th>8612104</th>\n      <td>blqyzd</td>\n      <td>124242</td>\n      <td>3</td>\n      <td>2017-08-05 14:25:33</td>\n    </tr>\n    <tr>\n      <th>8612105</th>\n      <td>blqyzd</td>\n      <td>948393</td>\n      <td>4</td>\n      <td>2017-08-05 13:25:21</td>\n    </tr>\n    <tr>\n      <th>8612106</th>\n      <td>blqyzd</td>\n      <td>163356</td>\n      <td>4</td>\n      <td>2017-08-05 14:24:57</td>\n    </tr>\n  </tbody>\n</table>\n<p>8612107 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_train.head(10)\n",
    "df_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10093/10093 [==============================] - 706s 70ms/step - loss: 0.6616 - val_loss: 0.6754\n",
      "Epoch 2/3\n",
      "10093/10093 [==============================] - 701s 69ms/step - loss: 0.6491 - val_loss: 0.6620\n",
      "Epoch 3/3\n",
      "10093/10093 [==============================] - 709s 70ms/step - loss: 0.6492 - val_loss: 0.6578\n"
     ]
    }
   ],
   "source": [
    "df_train, num_users, num_items, min_rating, max_rating = df_encoding(df_train)\n",
    "data = df_train.sample(frac=0.15, random_state=1111)\n",
    "\n",
    "# Assuming training on 80% of the data and validating on 20%.\n",
    "train_df = data.sample(frac=0.5, random_state=1111)\n",
    "val_df = df_train.drop(train_df.index)\n",
    "\n",
    "x_train,x_val = (train_df[[\"user\", \"item\"]].values,val_df[[\"user\", \"item\"]].values)\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y_train,y_val = (train_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values,val_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values)\n",
    "\n",
    "\n",
    "model = RecommenderNet(num_users, num_items, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0007),\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=3,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20184/20185 [============================>.] - ETA: 0s - loss: 0.6588"
     ]
    }
   ],
   "source": [
    "df_train, num_users, num_items, min_rating, max_rating = df_encoding(df_train)\n",
    "data = df_train.sample(frac=0.15, random_state=1111)\n",
    "\n",
    "# Assuming training on 80% of the data and validating on 20%.\n",
    "train_df = data.sample(frac=0.5, random_state=1111)\n",
    "val_df = df_train.drop(train_df.index)\n",
    "\n",
    "x_train,x_val = (train_df[[\"user\", \"item\"]].values,val_df[[\"user\", \"item\"]].values)\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y_train,y_val = (train_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values,val_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values)\n",
    "\n",
    "\n",
    "model = RecommenderNet(num_users, num_items, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0007),\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=3,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train, num_users, num_items, min_rating, max_rating = df_encoding(df_train)\n",
    "data = df_train.sample(frac=0.1, random_state=1111)\n",
    "\n",
    "# Assuming training on 80% of the data and validating on 20%.\n",
    "train_df = data.sample(frac=0.6, random_state=1111)\n",
    "val_df = df_train.drop(train_df.index)\n",
    "\n",
    "x_train,x_val = (train_df[[\"user\", \"item\"]].values,val_df[[\"user\", \"item\"]].values)\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y_train,y_val = (train_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values,val_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values)\n",
    "\n",
    "\n",
    "model = RecommenderNet(num_users, num_items, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0007),\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=3,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train, num_users, num_items, min_rating, max_rating = df_encoding(df_train)\n",
    "data = df_train.sample(frac=0.1, random_state=1111)\n",
    "\n",
    "# Assuming training on 80% of the data and validating on 20%.\n",
    "train_df = data.sample(frac=0.6, random_state=1111)\n",
    "val_df = df_train.drop(train_df.index)\n",
    "\n",
    "x_train,x_val = (train_df[[\"user\", \"item\"]].values,val_df[[\"user\", \"item\"]].values)\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y_train,y_val = (train_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values,val_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values)\n",
    "\n",
    "\n",
    "model = RecommenderNet(num_users, num_items, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0007),\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=3,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}